# An√°lisis de Concurrencia en √Årboles AVL

## Resumen Ejecutivo

Este documento analiza las implementaciones concurrentes de √°rboles AVL y sus limitaciones inherentes de paralelismo.

**Hallazgo Principal:** Los √°rboles AVL **NO escalan bien con multi-threading** debido a:
1. Contenci√≥n de locks en la ra√≠z
2. Estructura inherentemente secuencial (path desde ra√≠z a nodo)
3. Operaciones de rebalanceo que requieren locks exclusivos

## Implementaciones Concurrentes

### 1. AVLTreeConcurrent (Read-Write Locks)

**Estrategia:** `std::shared_mutex` (C++17)
- **Reads:** M√∫ltiples threads pueden leer simult√°neamente (`shared_lock`)
- **Writes:** Un solo thread puede escribir a la vez (`unique_lock`)

```cpp
class AVLTreeConcurrent {
    std::shared_mutex mutex_;  // Global read-write lock

    bool contains(const Key& key) const {
        std::shared_lock<std::shared_mutex> lock(mutex_);  // Shared
        // ... b√∫squeda ...
    }

    void insert(const Key& key, const Value& value) {
        std::unique_lock<std::shared_mutex> lock(mutex_);  // Exclusive
        // ... inserci√≥n y rebalanceo ...
    }
};
```

**Ventajas:**
- ‚úÖ Simple de implementar
- ‚úÖ Correct por dise√±o
- ‚úÖ Mejor rendimiento en workloads read-heavy

**Desventajas:**
- ‚ùå Lock global = cuello de botella
- ‚ùå Reads bloquean durante writes
- ‚ùå No permite verdadero paralelismo en writes

### 2. AVLTreeFineGrained (Per-Node Locking)

**Estrategia:** Cada nodo tiene su propio mutex

```cpp
struct Node {
    std::mutex node_mutex;  // Lock per-node
    // ... data ...
};
```

**T√©cnica:** Hand-over-hand locking (lock coupling)
1. Lock parent
2. Lock child
3. Release parent
4. Continue down tree

**Ventajas:**
- ‚úÖ Reduce contenci√≥n vs global lock
- ‚úÖ Permite m√°s paralelismo en operaciones en diferentes subtrees

**Desventajas:**
- ‚ùå Muy complejo de implementar correctamente
- ‚ùå Overhead de m√∫ltiples locks por operaci√≥n
- ‚ùå Deadlocks si no se hace cuidadosamente
- ‚ùå Rebalanceo require locks en m√∫ltiples nodos

### 3. Lock-Free (No Implementado)

**Por qu√© NO est√° implementado:**

Lock-free AVL trees son extremadamente complejos:
- Requieren **versioning de nodos**
- Necesitan **hazard pointers** o **epoch-based reclamation**
- Operaciones de rebalanceo son multi-node y at√≥micas
- Complejidad de implementaci√≥n > 10x vs versi√≥n con locks
- Performance beneficios marginales para √°rboles

**Alternativa:** Para casos donde se necesita true lock-free, usar:
- Skip Lists
- B+ Trees
- Hash Tables concurrentes

## Resultados de Benchmarks

### Configuraci√≥n
- **Operaciones:** 10,000 por thread
- **Key range:** 0-5,000
- **Workloads:** Read-heavy (90% reads), Mixed (50/50), Write-heavy (90% writes)

### Resultados (Read-Heavy, 90% reads)

| Threads | Single-threaded | Concurrent | Speedup | Efficiency |
|---------|-----------------|------------|---------|------------|
| 2 | baseline | 3.3M ops/sec | **0.17x** | 8.3% |
| 4 | baseline | 1.2M ops/sec | **0.03x** | 0.7% |
| 8 | baseline | 1.1M ops/sec | **0.01x** | 0.2% |

### Resultados (Write-Heavy, 90% writes)

| Threads | Single-threaded | Concurrent | Speedup | Efficiency |
|---------|-----------------|------------|---------|------------|
| 2 | baseline | 476K ops/sec | **0.02x** | 1.2% |
| 4 | baseline | 313K ops/sec | **0.02x** | 0.6% |
| 8 | baseline | 419K ops/sec | **0.03x** | 0.4% |

### üìä Gr√°fico de Scalability

```
Ideal Speedup vs Actual (Read-Heavy, 8 threads)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ideal:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 8.00x            ‚îÇ
‚îÇ Actual:   ‚ñè 0.01x                   ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ Efficiency: 0.2%                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Lock contention dominates!
```

## ¬øPor Qu√© NO Escala?

### 1. Amdahl's Law

**Ley de Amdahl:** Speedup m√°ximo limitado por porci√≥n serial

```
Speedup = 1 / (S + P/N)

Donde:
  S = fracci√≥n serial (acceso a ra√≠z)
  P = fracci√≥n paralela
  N = n√∫mero de threads
```

Para √°rboles AVL:
- **Toda operaci√≥n** comienza en la ra√≠z
- Ra√≠z es un **punto de serializaci√≥n**
- S ‚âà 80-90% (muy serial!)

### 2. Lock Contention

```
Thread 1: [trying to acquire lock]
Thread 2: [trying to acquire lock]  ‚Üê Esperando
Thread 3: [trying to acquire lock]  ‚Üê Esperando
Thread 4: [trying to acquire lock]  ‚Üê Esperando
Thread 1: [holding lock, doing work]
```

**Problema:** Threads pasan m√°s tiempo esperando locks que haciendo trabajo √∫til.

### 3. False Sharing (Fine-Grained Locking)

```cpp
struct Node {
    Key key;            // Cache line 0
    mutex lock;         // Cache line 0
    Node* left;         // Cache line 0
    Node* right;        // Cache line 0
};
```

Cuando thread A modifica un nodo, invalida cache line para thread B aunque est√©n accediendo nodos diferentes!

### 4. Tree Path Dependency

```
Operaci√≥n: insert(50)

Path: root(40) ‚Üí right(60) ‚Üí left(50)
       ‚Üì           ‚Üì            ‚Üì
     Lock1      Lock2        Lock3

Serial! No puede paralelizarse.
```

## Cuando Usar Concurrencia en √Årboles

### ‚úÖ S√ç Usar Concurrent AVL:

1. **Workload read-heavy extremo (>95% reads)**
   - M√∫ltiples readers sin contenci√≥n
   - Writes poco frecuentes

2. **M√∫ltiples clientes consultando datos inmutables**
   - API servers con cache
   - Read-only indices

3. **Cuando la alternativa es peor**
   - vs global mutex en toda la aplicaci√≥n
   - vs re-escribir desde cero

### ‚ùå NO Usar Concurrent AVL:

1. **High write contention**
   - Many threads insertando/eliminando
   - Frequent rebalancing

2. **Cuando necesitas high throughput**
   - Lock overhead > benefit
   - Single-threaded es m√°s r√°pido!

3. **Cuando hay alternativas mejores**
   - Hash tables concurrentes (mejor paralelismo)
   - B+ trees (menos rotaciones)
   - Skip lists (lock-free m√°s f√°cil)

## Alternativas para Alto Paralelismo

### 1. Concurrent Hash Table

```cpp
// Ejemplo: Intel TBB concurrent_hash_map
tbb::concurrent_hash_map<Key, Value> map;

// O(1) operations, excellent scalability
map.insert({key, value});
```

**Ventajas:**
- ‚úÖ O(1) operations
- ‚úÖ Scala linealmente con threads
- ‚úÖ Lock striping reduce contention

**Cu√°ndo usar:** No necesitas orden, solo lookup r√°pido

### 2. Skip List

```cpp
// Lock-free skip list
concurrent_skip_list<Key, Value> list;
```

**Ventajas:**
- ‚úÖ Lock-free posible
- ‚úÖ Operaciones probabilÔøΩÔøΩsticamente O(log n)
- ‚úÖ No rebalanceo = menos contention

**Cu√°ndo usar:** Necesitas orden + concurrencia

### 3. B+ Tree

```cpp
// Concurrent B+ tree
bplus_tree<Key, Value, PageSize=256> tree;
```

**Ventajas:**
- ‚úÖ Menos rotaciones que AVL
- ‚úÖ Cache-friendly (pages)
- ‚úÖ Optimistic locking funciona mejor

**Cu√°ndo usar:** Databases, filesystems

### 4. Particionamiento (Sharding)

```cpp
// Multiple independent AVL trees
vector<AVLTree<Key, Value>> shards(NUM_THREADS);

void insert(Key k, Value v) {
    int shard_id = hash(k) % NUM_THREADS;
    shards[shard_id].insert(k, v);
}
```

**Ventajas:**
- ‚úÖ Sin contenci√≥n entre shards
- ‚úÖ Scala linealmente
- ‚úÖ Simple de implementar

**Desventajas:**
- ‚ùå Range queries son complejas
- ‚ùå Rebalancing global dif√≠cil

## Recomendaciones

### Para Lectura Concurrente

**Use Case:** API server con cache read-heavy

```cpp
AVLTreeConcurrent<string, UserData> user_cache;

// 1000 requests/sec reading
thread pool: [read] [read] [read] [read] ...

// 10 requests/sec writing
thread: [write - blocks all readers briefly]

// Acceptable overhead!
```

### Para Write-Heavy

**NO usar AVL concurrent!** Use:

```cpp
// Option 1: Hash table
tbb::concurrent_hash_map<Key, Value> map;

// Option 2: Sharded AVL
struct ShardedAVL {
    vector<AVLTree<Key, Value>> shards;
    vector<mutex> shard_locks;

    void insert(Key k, Value v) {
        size_t shard = hash(k) % shards.size();
        lock_guard<mutex> lock(shard_locks[shard]);
        shards[shard].insert(k, v);
    }
};
```

## Mediciones y Profile

### C√≥mo Identificar Contention

```bash
# Usar perf (Linux)
perf record -g ./benchmark_mt
perf report

# Buscar:
# - High time in __lll_lock_wait (waiting for locks)
# - Flat profiles (no parallelism)
# - Context switches
```

### Metricas Importantes

1. **Lock Hold Time:** Cu√°nto tiempo se mantiene un lock
2. **Lock Wait Time:** Cu√°nto tiempo esperando por lock
3. **Contention Rate:** % tiempo en contention
4. **Speedup:** Actual vs Ideal
5. **Efficiency:** Speedup / NumThreads

### Ejemplo de Profile

```
Total time: 1000ms
Lock wait: 850ms   ‚Üê 85% waiting!
Actual work: 150ms ‚Üê Only 15% useful work

Conclusion: Lock contention dominates
Solution: Reduce critical sections or use different data structure
```

## Conclusiones

### üéØ Hallazgos Clave

1. **√Årboles AVL NO escalan bien** con multi-threading
   - Efficiency < 10% en todos los casos
   - Lock contention domina performance

2. **Read-Write locks ayudan** en workloads read-heavy
   - Pero speedup sigue siendo < 1x vs single-thread!

3. **Fine-grained locking** es complejo y no vale la pena
   - Overhead > benefits para √°rboles

4. **Alternativas son mejores** para concurrency
   - Hash tables, skip lists, B+ trees
   - O sharding de m√∫ltiples √°rboles

### üí° Cu√°ndo Es Aceptable

- Backend servers con >95% reads
- Rare updates, frequent queries
- Cuando ordering es CRITICAL (no puede usar hash)
- Performance no es cr√≠tico

### üö´ Cu√°ndo Evitar

- High write throughput necesario
- Performance-critical path
- Cuando hay alternativas (hash table, skip list)
- Single-threaded es suficiente

### üî¨ Para Investigaci√≥n Futura

1. **RCU (Read-Copy-Update)** para trees
2. **Optimistic concurrency control**
3. **MVCC** (Multi-Version Concurrency Control)
4. **GPU-accelerated** tree operations

## Referencias

### Papers

- "The Art of Multiprocessor Programming" - Herlihy & Shavit
- "Concurrent Data Structures" - Moir & Shavit
- "Non-blocking Data Structures with Hazard Pointers" - Michael

### Libros

- "C++ Concurrency in Action" - Anthony Williams
- "Java Concurrency in Practice" - Goetz et al

### Implementaciones Existentes

- Intel TBB (Threading Building Blocks)
- Folly (Facebook Open Source Library)
- Boost.Lockfree

---

**Conclusi√≥n Final:** Para la mayor√≠a de casos de uso concurrentes, **NO uses AVL trees concurrentes**. Usa estructuras dise√±adas para concurrencia desde el inicio (hash tables, skip lists). Si necesitas ordering + concurrencia, considera sharding o B+ trees.

**La concurrencia bien hecha es dif√≠cil. Las estructuras de datos concurrentes son a√∫n m√°s dif√≠ciles.**
